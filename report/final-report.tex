%File: formatting-instructions-latex-2025.tex
%release 2025.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}

\hbadness=1500
\usepackage{tabularray}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

\input{macros}

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Rideshare Pilots \\ \large Assisted Matching via Planning and Acting in Simulated Environments}
\author{
    Addison Hanrattie\\
    \href{https://github.com/supersimple33/rideshare-pilots}{Project link}
}
\affiliations{
    University of Maryland\\
    ahanratt@umd.edu
}

\nocopyright
\usepackage{tabularray}  % for the assessment table

\begin{document}

\maketitle

\input{checklist-and-assessment}


%==========================================================
%==========================================================
\section{Introduction}

Within the rideshare domain, a very common pain point is connecting with the rider with their matched driver. This is especially true in scenarios where there are likely to be a very large number of riders searching for rides, such as at a concert or sporting event. In these scenarios, it is common for riders to be matched with drivers that are not in their immediate vicinity, and thus the rider must navigate to the driver. This can be a difficult task, especially if the rider is unfamiliar with the area or if there are obstacles in the way.

While much attention in AI planning has been focused on achieving the best possible planning performance and plan quality little attention has been given to leveraging the ability to simulate people as actors in the environment. In this project, we simulate a rideshare user attempting to find their assigned car in a parking lot. Rather than identifying the best possible plan to find the car, we investigate how different environments effect the ability of an agent to find their car when acting in the environment with a simple planning and acting algorithm. This allows us to ultimately draw conclusions about how different environment characteristics effect the ability of an agent to successfully find their car with the hope being that these insights can be used to design better human rideshare experiences in the future. As rideshare services move towards greater autonomy and uniformity in car design, it is important to maximize the efficiency of the particularly human intensive tasks.

%==========================================================
%==========================================================
\section{Background}

The motivation for this project builds on concepts introduced in earlier work that highlighted a gap in research on the final 100 yards of on-foot navigation within the broader last-mile problem~\cite{sametPILOTPilotingLast2024}. We acknowledge that the difficulties faced by riders in locating their car once in a general vicinity (ie parking lot) are especially unique as compared to simply walking to said area from an original starting location. Prior work has explored the challenges of on-foot navigation in urban environments, but there is a lack of research specifically addressing the nuances of the search task that is rideshare pickup.

The issue of locating a rideshare vehicle goes far beyond simple time efficiency savings. There have been numerous cases of riders entering the wrong vehicle and being physically harmed such as the case of Samantha Josephson who was murdered after entering a car she thought was her Uber. This case and others motivated the creation of Sami's law~\cite{smithSamisLaw2023} which requires a study to be done on the number of assaulted riders each year and the safety measures taken. In general there is very little regulation around rideshare safety within the US as compared to countries like China~\cite{stemlerDataPrivacyRegulation2025} which regulate where and how rideshare pickups can occur. Therefore the lessons learned from this project should not only be used to improve efficiency but also safety of rideshare pickups ensuring that riders can quickly and accurately and safely find their rideshare vehicle.

The main planner for this project is inspired by \HTNRunLookahead, \cite{ghallabActingPlanningLearning2025}, Algorithm~6.3. Briefly, this acting algorithm checks whether the agent has reached the goal. If an existing plan exists and \alg{Simulate} is not failure, it performs the next action in the plan. Otherwise it creates a new plan. It also uses some elements of the repairing scheme from~\cite{ghallabActingPlanningLearning2025}, Algorithm~6.4.

% (Notice the use of macros from the `macro.tex` file -- these are optional but can really improve the readability of your report.)
%On the other hand, some of you created your own procedures or used something from the literature.  In that case, it might be a good idea to include pseudocode if you modified something from the book or created your own algorithm.  I don't really want you to worry about using the algorithmic environment.  For purposes of this report, I will accept psuedocode `lite', which is basically the text like we have been using all semester, similar to the following:
%\begin{scriptsize}
%\begin{verbatim}
%    procedure CrossPrint(arg1, arg2, arg3)
%    Q := { arg1 x arg2 }
%    while |Q| < arg3:
%        print This statement is false.
%        unused_item = pop(Q)
%\end{verbatim}
%\end{scriptsize}

%==========================================================
%==========================================================
\section{Approach}

The primary methodological challenge in this project was modeling the inherently human element of search and decision-making in the final 100 yards of ride-hailing pickup. Two distinct human factors were addressed: (i) the behavioral characteristics of pedestrian movement [one cannot just walk across a busy street] and (ii) imperfect or incomplete knowledge about the locations of vehicles due to limited perception range.

To reduce problem complexity while preserving the core decision structure, agent movement was discretized to a uniform grid. Although this abstraction does not fully reflect the continuous motion of real life, it allowed the planning model to operate on a tractable state space and supported reproducible experimentation. In addition, the agent was assumed to perceive vehicles in all directions but could only verify the identity of a vehicle only when physically located near it or near a assistant which could direct the agent. This mirrors real-world conditions in which riders may be able to see a vehicle at a distance but cannot confirm that it is their assigned car until they reach it unless otherwise advised. This assumption also constituted a controlled simplification of the visual uncertainty present in practice.

%--------------------------------
\subsection{Environment}

The interactive environment was implemented as a gridworld simulator in python using Gymnasium~\cite{towersGymnasiumStandardInterface2025a}. The environment was hand crafted to allow for easy modification and to ensure a faithful representation of the rideshare pickup task. The environment consist of a grid representing a parking lot with obstacles, a single agent representing the rider, a single target vehicle representing the assigned rideshare car, numerous distractor vehicles representing other cars in the lot, and numerous assistants representing people in the lot who can help the agent find their car. The agent can move in four cardinal directions, observe its surroundings, and gain insights from nearby assistants. The goal of the agent is to find and reach the target vehicle in as few steps as possible. To prevent the planner from exploiting privileged information, all vehicles are rendered indistinguishable up to a certain viewing distance even if obstacles could be seen further beyond. 

When resetting the environment a obstacle generator may be supplied. This generator is responsible for placing obstacles in the environment according to some distribution. The default generator used would take a count of obstacles and their maz size and then uniformly choose random locations to seed the obstacles and then uniformly grow them along the perimeter until they reached their maximum size or were otherwise constrained. It can also be noted that all of the actors are also placed uniformly randomly across the grid. 

The perception of the agent is limited in the following manor. After any given step a $N \times N$ square centered on the agent is extracted and then any point which in non navigable within the area is labelled out of sight. Finally if any in-sight vehicles are outside of a manhattan distance of $M$ from the agent they are labelled as unknown vehicles. This process ensures that the agent can only see a limited area around itself and cannot identify (but can observe) vehicles at a distance. However if an assistant is within the viewing distance of the agent then the assistant can inform the agent of the identity of any in-sight vehicles.

%--------------------------------
\subsection{Planning Approach}
At the heart of our approach is a simple Hierarchical Task Network (HTN) planner with a few common sense methods for finding the target. 
The planner is implemented in standard python without the support of any planning libraries. While not directly named the planner has two methods which can be used to form plans: \texttt{navigate\_to\_point}, \texttt{explore\_environment}. These refinement methods use the base actions of \texttt{perceive} and \texttt{move} to form themselves.
The \texttt{perceive} action allows the agent to look around its current position and identify any vehicles, obstacles, or assistants within its viewing distance. 
The \texttt{move} action allows the agent to move one step in any of the four cardinal directions, provided there is no obstacle in the way.
The \texttt{navigate\_to\_point} method allows the agent to create a plan to move to a specific point in the environment using \astar search (it is actually bi-astar since that runs even faster).
The \texttt{explore\_environment} method allows the agent to create a plan to explore the environment in a systematic way, visiting all points within its viewing distance. 
Specifically this is done by recursively calling \texttt{navigate\_to\_point} on the nearest unexplored point until the target has been located.
Once the target has been located, the \texttt{move\_to\_point} method allows the agent to create a plan to move directly to the target vehicle and begin its ride.

%--------------------------------
\subsection{Acting Approach}

Since the environment is dynamic the content that a given space is associated with may change over time. For example, a car may begin as an unknown space but once perceived it may be identified to be a distractor vehicle. If said distractor vehicle is in the way of the agent's current plan to reach the target vehicle then the plan must be repaired. To handle this dynamic environment we focus on using online methods that interleave the planning and acting. The main acting algorithm is inspired by \HTNRunLookahead. Specifically, at each time step before acting we pop the next move action from the current plan and simulate it. If the simulation is successful (ie the space is safe to move into) then it is executed in the environment. If the simulation fails then a new plan is created from the current state which focuses on identifying a new route to the point of focus. This process continues until the agent reaches the target vehicle.


%==========================================================
%==========================================================
\section{Evaluation Plan}

Within the simplified setup described above, venue owners largely have two controls. Firstly they can control the density and prevalence and pattern of obstacles within the parking lot. Secondly they can control the number and distribution of assistants within the parking lot. Therefore we focus our evaluation on how these two independent variables effect the ability of the agent to find their car. As well as how other meta-variables such as the size of the parking lot and the viewing distance of the agent effect performance. This extra analysis is important for better understanding how the environment operates and how different components interact and influence one another. It is important to note here that the distance at which a car can be identified may also be influenced by factors which are within a venues control such as clearly labelling sections of a garage however those improvements and the variable as it is reflected here is not a direct relationship.

\paragraph{Independent variables}
For our first experiment we investigate the effects of obstacle density and size on the ability of the agent to find their car. We start with a grid of size $18 \times 18$, view sizes of $9 \times 9$, no obscurity, and no fake targets. We vary the following independent variables:

\begin{itemize}
    \item \textbf{Obstacle occurrence rate:} This variable controls the maximum density of obstacles within the parking lot. We vary this from 1 obstacle to 10 obstacles.
    \item \textbf{Obstacle size:} This variable controls the maximum size of obstacles within the parking lot. We vary this from small obstacles consisting of 2 blocked spaces up to a size of 20 blocked spaces.
\end{itemize}

For each of the following experiments we run experiments on each of the following parking lot sizes: a small lot of size $12 \times 12$, a medium lot of size $24 \times 24$, and a large lot of size $36 \times 36$. Additionally for each board size we run the experiment on each of the following combinations of obstacle distributions. This is done to ensure we control that any of the following tested independent variables effects are not due to a preference on the selected obstacle distribution. We ensure across all of the settings that the same number of points are blocked to ensure a fair comparison. The obstacle distributions used are as follows:

\begin{itemize}
    \item \textbf{Many Dots:} Numerous small obstacles scattered randomly throughout the parking lot.
    \item \textbf{Normal:} A moderate number of medium sized obstacles scattered throughout the parking lot.
    \item \textbf{Few Big:} A small number of large obstacles scattered throughout the parking lot.
\end{itemize}

The first two experiments we run focus on tuning choices of the environment specifically the view size of the agent $N$ and the distance at which a car can be identified $M$. For the first experiment the number of fake targets is kept constant at $5$ and a car can be identified at any distance. For the second experiment the number of fake targets is kept constant at $5$ again and the viewing distance is kept constant at $11 \times 11$. For both experiments we vary the independent variable as follows: rolling the view distance from $3$ to $11$ in increments of $2$ and rolling the identify distance from $1$ to $11$ in increments of $1$.

The final experiment we run focuses on the effects of assistant count on the ability of the agent to find their car. For this experiment we keep the viewing distance at $11 \times 11$, the number of fake targets at $5$, and the identify distance at $3$. We vary the independent variable as follows: rolling the assistant count from $0$ to $7$ in increments of $1$.

\paragraph{Dependent variables}
The main dependent variable of interest across all experiments is the average number of steps taken by the agent to find their car. This metric directly reflects the efficiency of the agent in completing the task. Furthermore, it is a reasonable proxy for rider searching / walking time in real-world scenarios, which is a critical factor in user satisfaction with rideshare services. By minimizing the number of steps taken to locate the vehicle, we can infer that the agent is effectively navigating the environment and leveraging available resources (like assistants) to optimize its search strategy.

%==========================================================
%==========================================================
\section{Results}

\paragraph{Local View Size}
The first of the two meta-variable tuning experiments focused on the effects of viewing distance on the ability of the agent to find their car. The results of this experiment can be seen in Figure~\ref{fig:viewing-distance-all} and Figure~\ref{fig:viewing-distance-combo}. As expected increasing the viewing distance of the agent has a significant positive effect on the ability of the agent to find their car. This is almost definitely due to the fact that with a larger viewing distance the agent can see more of the environment at any given time and thus can make more informed decisions about where to move next. It is also interesting to note that the effect of viewing distance is more pronounced in larger parking lots in terms of the total number of steps saved but worse in terms of percentage improvement. This is likely due to the fact that in larger parking lots there is more area to cover and thus the agent can benefit more from being able to see more of the environment at any given time. However, since the total number of steps taken is also larger in larger parking lots, the percentage improvement is smaller. 

The relationship observed was clearly linear and the relationship can be seen in Table~\ref{tab:radius-linear-fit}. For the small, medium, and large parking lots the cost savings per radius increase was found to be $9.30$, $29.51$, and $50.27$ respectively when averaged across the three obstacle distributions. It is interesting to note that the savings seem as though they may scale linearly with the size of the parking lot as well.

\paragraph{Identification Distance}
The second of the two meta-variable tuning experiments focused on the effects of identification distance on the ability of the agent to find their car. The results of this experiment can be seen in Figure~\ref{fig:obscurity-all} and Figure~\ref{fig:obscurity-combo}. As expected increasing the identification distance of the agent has a significant positive effect on the ability of the agent to find their car. It seems clear this is due to the fact that with a larger identification distance the agent can more easily identify their car from a distance and thus can make more informed decisions about where to move next and better sort between negative examples and positive examples. Again we see that the effect of identification distance is more pronounced in larger parking lots in terms of the total number of steps saved but worse in terms of percentage improvement. This is likely due to the same reasons as mentioned above. 

The relationship observed appears to be a exponential decay to a asymptote which is dependent on the board size. It can also be noted that the decay rate is much shallower for the larger parking lots. This would seem to indicate that identification distance is especially important in smaller parking lots but that its importance diminishes in larger parking lots where ability to effectively plan more forward thinking routes is more important.

\paragraph{Obstacle Count and Size}
The first of our two main experiments focuses on the effects of obstacle count and size on the ability of the agent to find their car. The results of this experiment can be seen in Figure~\ref{fig:obstacle-distribution}. Interestingly here we see that obstacle count and size has a positive effect on the ability of the agent to find their car. This is interesting as one would expect that the more obstacles there are in the environment the harder it would be for the agent to find their car. However, it seems that the obstacles actually help to structure the environment and provide more information to the agent about where to search. This is likely due to the fact that with more obstacles the agent can better segment the environment into smaller areas and thus can make more informed decisions about where to move next. It is also possible that with more obstacles there are more dead ends and thus the agent can more easily eliminate areas of the environment from consideration. This is supported by the fact that the obstacle count seems to have a greater effect than obstacle size which would make sense as a greater count leads to more segmentations of the environment.

\paragraph{Assistant Count}
The second of our two main experiments focuses on the effects of assistant count on the ability of the agent to find their car. The results of this experiment can be seen in Figure~\ref{fig:helper-all} and Figure~\ref{fig:helper-combo}. As expected increasing the number of assistants in the environment has a significant positive effect on the ability of the agent to find their car. Much like with the car identification distance this is likely due to the fact that with more assistants the agent can more easily identify their car from a distance and thus can make more informed decisions about where to move next and better sort between negative examples and positive examples. 

In the case of the smaller parking lot nearly all of the benefit is gained by the first assistant with very little gained thereafter. This would seem to suggest that in smaller parking lots a single assistant is sufficient to rapidly speed up the rate at which the agent can find their car. However, in the case of the medium and large parking lots we see that while the first assistant again provides the largest boost in performance there is still significant benefit to be gained from additional assistants (with the large parking lot having the longest tail). Thus it seems that in larger parking lots having multiple assistants is needed to maximally speed up the rate at which the agent can find their car.

\subsubsection{Summary}
In summary, our results indicate that several environmental factors significantly influence the efficiency of an agent in locating its assigned vehicle in a rideshare pickup scenario. Our first finding was that providing structure to the environment in the form of obstacles can actually aid the agent in its search task, likely by segmenting the environment and reducing the effective search space. Secondly, enhancing the agent's perceptual capabilities, such as by having clearer labels for car space numbers (increasing identification distance), substantially improves search efficiency, particularly in smaller environments. Lastly, the presence of even just a single human assistant which can pilot riders to their vehicles dramatically reduces search time.

%--------------------------------
\subsection{Discussion of Tradeoffs and Limitations}

The particular difficulty here is using planning and acting methods to gain an understanding of how best to structure real world environments for human riders no matter how effective (or ineffectively) they can plan. Thus the biggest limitation here is the fact that we are using a simplified gridworld environment to model a complex real world task. While this simplification allows us to more easily control and manipulate the environment it also means that our results may not fully generalize to real world scenarios. Additionally, our relatively simple planner does not incorporate more advanced techniques such as learning or probabilistic reasoning which may be more effective in real world scenarios. However this is not necessarily a bad thing as the methods described may be exactly how humans approach the problem of finding their car in a parking lot. Nevertheless, future work could focus on increasing the number of different planning methods utilized to ensure that the results are maximized for all possible planning methods just as one would want to maximize for all possible human behaviors. Following this line of thought it would also be interesting to incorporate more realistic human behavior models into the environment to better simulate how humans would actually behave in these scenarios. The first of which could be as simple as adding some noise to the agent's movement or perception as well as more complex models such as causing agents to forget previous observations over time (allow them to get lost). Another way to generate new planning methods which doesn't involve hard coding elements could be to use a reinforcement learning approach based on a LSTM neural network to learn a policy for finding the car in the environment as this could better simulate how humans learn to navigate environments over time. Another could be to use the method learning techniques as described in \cite{ghallabActingPlanningLearning2025}, Chapter~7 to more naturally learn new methods and then sanity check them against human behavior.

Other limitations come in the form of how the environment mimics reality. The generation follows uniform seeding whereas in the real world there is far more structure to these parking lots. Thus future work could focus on generating more realistic parking lot environments to better simulate real world scenarios. This could include generating parking lots with rows and aisles as well as more dynamic obstacles such as crosswalks. Furthermore the agent views the world in a top down sense whereas in reality humans have a first person view of the world. Thus future work could focus on implementing a first person view akin to that of the flatlands to better simulate real world scenarios.

As with all projects more data analysis and experiments could be run to better understand the effects of the independent variables on the dependent variable. This could include running more trials to ensure statistical significance as well as running more experiments to better understand the interactions between the independent variables such as increasing board sizes beyond $36 \times 36$ or varying the number of fake targets in the environment to be even greater. Future work could also take a more nuanced work on the dependent variable such as setting benchmarks and seeing how many trials fall within a certain threshold of the benchmark or also measuring the variance of the results to better understand the consistency of the agent's performance.

Finally, developing a better analog between the simulation here and real behavior and quantifying the extent to which the results here generalize to real world scenarios is an important next step. It is pretty obvious that adding in human helpers would assist people in getting to their cars faster, but what matters for event organizers is whether or not it is worth it to hire those helpers. Thus, running user studies where people are asked to find their cars in a parking lot with varying numbers of helpers and measuring the time taken to find their cars would be a great next step. This would allow us to directly measure the extent to which the results here generalize to real world scenarios and provide more concrete recommendations for event organizers.

%==========================================================
%==========================================================
\section{What I learned}

\begin{itemize}
    \item How to implement a Gymnasium environment from scratch and test it effectively.
    \subitem How to debug said environment when it inevitably breaks lots of times.
    \item How to write strongly typed python code using type hints and how to keep consist dependency management using uv (This code is heavily productionized and other than the simplifications I would feel confident sending it to venue owners and letting them add their venues in as maps).
    \item How to optimize my code using numpy so that it runs really fast (we can initialize 2000 games per second and take over 15,000 steps per second on my laptop).
    \item How to implement a simple HTN planner and acting algorithm in python.
    \item How to design and run experiments on planning and acting systems which investigate the effects of environmental factors on planning and acting performance.
\end{itemize}

\section{Acknowledgements}

I would like to thank Professor Dana Nau and his co-authors, for writing a great book to read out of. Dr.\ Roberts for his help in guiding this project and teaching me this course. Finally, I would like to thank Dr.\ Samet for his help in brainstorming ideas for this project.


\clearpage  %leave this command here so the tables and figures start on a new page
%==========================================================
%==========================================================
\section{Summary Figures and Tables}
\label{sec:figures-and-tables}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/view_size_all.png}
    \caption{Effect of viewing distance on the ability of the agent to find their car across all trials.}
    \label{fig:viewing-distance-all}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/view_size_combo.png}
    \caption{Effect of viewing distance on the ability of the agent to find their car averaged across obstacle distributions.}
    \label{fig:viewing-distance-combo}
\end{figure}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\toprule
\textbf{Board Size / Scheme} & \textbf{Slope} & \textbf{Intercept} & $\mathbf{R^{2}}$ \\
\midrule
Small Normal      & -4.80  & 65.38  & 0.98 \\
Small Many Small  & -4.68  & 64.85  & 0.98 \\
Small Big         & -4.46  & 62.23  & 0.98 \\
\midrule
Medium Normal     & -13.75 & 284.72 & 0.99 \\
Medium Many Small & -15.26 & 294.45 & 0.99 \\
Medium Big        & -15.25 & 297.56 & 0.97 \\
\midrule
Large Normal      & -25.32 & 664.00 & 0.99 \\
Large Many Small  & -25.76 & 663.14 & 1.00 \\
Large Big         & -24.33 & 654.07 & 1.00 \\
\bottomrule
\end{tabular}
\caption{Linear fit parameters for game length vs. diameter across board sizes and obstacle schemes.}
\label{tab:radius-linear-fit}
\end{table}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/obscurity_all.png}
    \caption{Effect of identification distance on the ability of the agent to find their car across all trials.}
    \label{fig:obscurity-all}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/obscurity_combo.png}
    \caption{Effect of identification distance on the ability of the agent to find their car averaged across obstacle distributions.}
    \label{fig:obscurity-combo}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/obstacle_distribution.png}
    \caption{Effect of obstacle count and size on the ability of the agent to find their car averaged across viewing distances.}
    \label{fig:obstacle-distribution}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/helper_all.png}
    \caption{Effect of assistant count on the ability of the agent to find their car across all trials.}
    \label{fig:helper-all}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/helper_combo.png}
    \caption{Effect of assistant count on the ability of the agent to find their car averaged across obstacle distributions.}
    \label{fig:helper-combo}
\end{figure}


%==========================================================
%==========================================================
\bibliography{aaai25}


%==========================================================
%==========================================================
%==========================================================
%==========================================================
\clearpage    %leave this command here so the appendices start on a new page
\appendix

\end{document}
