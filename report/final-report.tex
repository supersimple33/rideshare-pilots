%File: formatting-instructions-latex-2025.tex
%release 2025.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}

\hbadness=1500
\usepackage{tabularray}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

\input{macros}

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Rideshare Pilots \\ \large Assisted Matching via Planning and Acting in Simulated Environments}
\author{
    Addison Hanrattie\\
    \href{https://github.com/supersimple33/rideshare-pilots}{Project link}
}
\affiliations{
    University of Maryland\\
    ahanratt@umd.edu
}

\nocopyright
\usepackage{tabularray}  % for the assessment table

\begin{document}

\maketitle

\input{checklist-and-assessment}


%==========================================================
%==========================================================
\section{Introduction}

Within the rideshare domain, a very common pain point is connecting with the rider with their matched driver. This is especially true in scenarios where there are likely to be a very large number of riders searching for rides, such as at a concert or sporting event. In these scenarios, it is common for riders to be matched with drivers that are not in their immediate vicinity, and thus the rider must navigate to the driver. This can be a difficult task, especially if the rider is unfamiliar with the area or if there are obstacles in the way.

While much attention in AI planning has been focused on achieving the best possible planning performance and plan quality little attention has been given to leveraging the ability to simulate people as actors in the environment. In this project, we simulate a rideshare user attempting to find their assigned car in a parking lot. Rather than identifying the best possible plan to find the car, we investigate how different environments effect the ability of an agent to find their car when acting in the environment with a simple planning and acting algorithm. This allows us to ultimately draw conclusions about how different environment characteristics effect the ability of an agent to successfully find their car with the hope being that these insights can be used to design better human rideshare experiences in the future. As rideshare services move towards greater autonomy and uniformity in car design, it is important to maximize the efficiency of the particularly human intensive tasks.

%==========================================================
%==========================================================
\section{Background}

The motivation for this project builds on concepts introduced in earlier work that highlighted a gap in research on the final 100 yards of on-foot navigation within the broader last-mile problem~\cite{sametPILOTPilotingLast2024}. We acknowledge that the difficulties faced by riders in locating their car once in a general vicinity (ie parking lot) are especially unique as compared to simply walking to said area from an original starting location. Prior work has explored the challenges of on-foot navigation in urban environments, but there is a lack of research specifically addressing the nuances of the search task that is rideshare pickup.

The issue of locating a rideshare vehicle goes far beyond simple time efficiency savings. There have been numerous cases of riders entering the wrong vehicle and being physically harmed such as the case of Samantha Josephson who was murdered after entering a car she thought was her Uber. This case and others motivated the creation of Sami's law~\cite{smithSamisLaw2023} which requires a study to be done on the number of assaulted riders each year and the safety measures taken. In general there is very little regulation around rideshare safety within the US as compared to countries like China~\cite{stemlerDataPrivacyRegulation2025} which regulate where and how rideshare pickups can occur. Therefore the lessons learned from this project should not only be used to improve efficiency but also safety of rideshare pickups ensuring that riders can quickly and accurately and safely find their rideshare vehicle.

The main planner for this project is inspired by \HTNRunLookahead, \cite{ghallabActingPlanningLearning2025}, Algorithm~6.3. Briefly, this acting algorithm checks whether the agent has reached the goal. If an existing plan exists and \alg{Simulate} is not failure, it performs the next action in the plan. Otherwise it creates a new plan. It also uses some elements of the repairing scheme from~\cite{ghallabActingPlanningLearning2025}, Algorithm~6.4.

% (Notice the use of macros from the `macro.tex` file -- these are optional but can really improve the readability of your report.)
%On the other hand, some of you created your own procedures or used something from the literature.  In that case, it might be a good idea to include pseudocode if you modified something from the book or created your own algorithm.  I don't really want you to worry about using the algorithmic environment.  For purposes of this report, I will accept psuedocode `lite', which is basically the text like we have been using all semester, similar to the following:
%\begin{scriptsize}
%\begin{verbatim}
%    procedure CrossPrint(arg1, arg2, arg3)
%    Q := { arg1 x arg2 }
%    while |Q| < arg3:
%        print This statement is false.
%        unused_item = pop(Q)
%\end{verbatim}
%\end{scriptsize}

%==========================================================
%==========================================================
\section{Approach}

The primary methodological challenge in this project was modeling the inherently human element of search and decision-making in the final 100 yards of ride-hailing pickup. Two distinct human factors were addressed: (i) the behavioral characteristics of pedestrian movement [one cannot just walk across a busy street] and (ii) imperfect or incomplete knowledge about the locations of vehicles due to limited perception range.

To reduce problem complexity while preserving the core decision structure, agent movement was discretized to a uniform grid. Although this abstraction does not fully reflect the continuous motion of real life, it allowed the planning model to operate on a tractable state space and supported reproducible experimentation. In addition, the agent was assumed to perceive vehicles in all directions but could only verify the identity of a vehicle only when physically located near it or near a assistant which could direct the agent. This mirrors real-world conditions in which riders may be able to see a vehicle at a distance but cannot confirm that it is their assigned car until they reach it unless otherwise advised. This assumption also constituted a controlled simplification of the visual uncertainty present in practice.

%--------------------------------
\subsection{Environment}

The interactive environment was implemented as a gridworld simulator in python using Gymnasium. The environment was hand crafted to allow for easy modification and to ensure a faithful representation of the rideshare pickup task. The environment consist of a grid representing a parking lot with obstacles, a single agent representing the rider, a single target vehicle representing the assigned rideshare car, numerous distractor vehicles representing other cars in the lot, and numerous assistants representing people in the lot who can help the agent find their car. The agent can move in four cardinal directions, observe its surroundings, and gain insights from nearby assistants. The goal of the agent is to find and reach the target vehicle in as few steps as possible. To prevent the planner from exploiting privileged information, all vehicles are rendered indistinguishable up to a certain viewing distance even if obstacles could be seen further beyond. 

When resetting the environment a obstacle generator may be supplied. This generator is responsible for placing obstacles in the environment according to some distribution. The default generator used would take a count of obstacles and their maz size and then uniformly choose random locations to seed the obstacles and then uniformly grow them along the perimeter until they reached their maximum size or were otherwise constrained. It can also be noted that all of the actors are also placed uniformly randomly across the grid. 

The perception of the agent is limited in the following manor. After any given step a $N \times N$ square centered on the agent is extracted and then any point which in non navigable within the area is labelled out of sight. Finally if any in-sight vehicles are outside of a manhattan distance of $M$ from the agent they are labelled as unknown vehicles. This process ensures that the agent can only see a limited area around itself and cannot identify (but can observe) vehicles at a distance. However if an assistant is within the viewing distance of the agent then the assistant can inform the agent of the identity of any in-sight vehicles.

%--------------------------------
\subsection{Planning Approach}
At the heart of our approach is a simple Hierarchical Task Network (HTN) planner with a few common sense methods for finding the target. 
The planner is implemented in standard python without the support of any planning libraries. While not directly named the planner has two methods which can be used to form plans: \texttt{navigate\_to\_point}, \texttt{explore\_environment}. These refinement methods use the base actions of \texttt{perceive} and \texttt{move} to form themselves.
The \texttt{perceive} action allows the agent to look around its current position and identify any vehicles, obstacles, or assistants within its viewing distance. 
The \texttt{move} action allows the agent to move one step in any of the four cardinal directions, provided there is no obstacle in the way.
The \texttt{navigate\_to\_point} method allows the agent to create a plan to move to a specific point in the environment using \astar search (it is actually bi-astar since that runs even faster).
The \texttt{explore\_environment} method allows the agent to create a plan to explore the environment in a systematic way, visiting all points within its viewing distance. 
Specifically this is done by recursively calling \texttt{navigate\_to\_point} on the nearest unexplored point until the target has been located.
Once the target has been located, the \texttt{move\_to\_point} method allows the agent to create a plan to move directly to the target vehicle and begin its ride.

%--------------------------------
\subsection{Acting Approach}

Since the environment is dynamic the content that a given space is associated with may change over time. For example, a car may begin as an unknown space but once perceived it may be identified to be a distractor vehicle. If said distractor vehicle is in the way of the agent's current plan to reach the target vehicle then the plan must be repaired. To handle this dynamic environment we focus on using online methods that interleave the planning and acting. The main acting algorithm is inspired by \HTNRunLookahead. Specifically, at each time step before acting we pop the next move action from the current plan and simulate it. If the simulation is successful (ie the space is safe to move into) then it is executed in the environment. If the simulation fails then a new plan is created from the current state which focuses on identifying a new route to the point of focus. This process continues until the agent reaches the target vehicle.


%==========================================================
%==========================================================
\section{Evaluation Plan}

Within the simplified setup described above, venue owners largely have two controls. Firstly they can control the density and prevalence and pattern of obstacles within the parking lot. Secondly they can control the number and distribution of assistants within the parking lot. Therefore we focus our evaluation on how these two independent variables effect the ability of the agent to find their car. As well as how other meta-variables such as the size of the parking lot and the viewing distance of the agent effect performance. This extra analysis is important for better understanding how the environment operates and how different components interact and influence one another. It is important to note here that the distance at which a car can be identified may also be influenced by factors which are within a venues control such as clearly labelling sections of a garage however those improvements and the variable as it is reflected here is not a direct relationship.

\paragraph{Independent variables}
For our first experiment we investigate the effects of obstacle density and size on the ability of the agent to find their car. We vary the following independent variables:

\begin{itemize}
    \item \textbf{Obstacle occurrence rate:} This variable controls the maximum density of obstacles within the parking lot. We vary this from 1 obstacle to 10 obstacles.
    \item \textbf{Obstacle size:} This variable controls the maximum size of obstacles within the parking lot. We vary this from small obstacles consisting of 2 blocked spaces up to a size of 20 blocked spaces.
\end{itemize}

For each of the following experiments we run experiments on each of the following parking lot sizes: a small lot of size $12 \times 12$, a medium lot of size $24 \times 24$, and a large lot of size $36 \times 36$. Additionally for each board size we run the experiment on each of the following combinations of obstacle distributions. This is done to ensure we control that any of the following tested independent variables effects are not due to a preference on the selected obstacle distribution. We ensure across all of the settings that the same number of points are blocked to ensure a fair comparison. The obstacle distributions used are as follows:

\begin{itemize}
    \item \textbf{Many Dots:} Numerous small obstacles scattered randomly throughout the parking lot.
    \item \textbf{Normal:} A moderate number of medium sized obstacles scattered throughout the parking lot.
    \item \textbf{Few Big:} A small number of large obstacles scattered throughout the parking lot.
\end{itemize}

The first two experiments we run focus on tuning choices of the environment specifically the view size of the agent $N$ and the distance at which a car can be identified $M$. For the first experiment the number of fake targets is kept constant at $5$ and a car can be identified at any distance. For the second experiment the number of fake targets is kept constant at $5$ again and the viewing distance is kept constant at $11 \times 11$. For both experiments we vary the independent variable as follows: rolling the view distance from $3$ to $11$ in increments of $2$ and rolling the identify distance from $1$ to $11$ in increments of $1$.

The final experiment we run focuses on the effects of assistant count on the ability of the agent to find their car. For this experiment we keep the viewing distance at $11 \times 11$, the number of fake targets at $5$, and the identify distance at $3$. We vary the independent variable as follows: rolling the assistant count from $0$ to $7$ in increments of $1$.

\paragraph{Dependent variables}
The main dependent variable of interest across all experiments is the average number of steps taken by the agent to find their car. This metric directly reflects the efficiency of the agent in completing the task. Furthermore, it is a reasonable proxy for rider searching / walking time in real-world scenarios, which is a critical factor in user satisfaction with rideshare services. By minimizing the number of steps taken to locate the vehicle, we can infer that the agent is effectively navigating the environment and leveraging available resources (like assistants) to optimize its search strategy.

%==========================================================
%==========================================================
\section{Results}

\paragraph{Local View Size}
The first of the two meta-variable tuning experiments focused on the effects of viewing distance on the ability of the agent to find their car. The results of this experiment can be seen in Figure~\ref{fig:viewing-distance-all} and Figure~\ref{fig:viewing-distance-combo}. As expected increasing the viewing distance of the agent has a significant positive effect on the ability of the agent to find their car. This is almost definitely due to the fact that with a larger viewing distance the agent can see more of the environment at any given time and thus can make more informed decisions about where to move next. It is also interesting to note that the effect of viewing distance is more pronounced in larger parking lots in terms of the total number of steps saved but worse in terms of percentage improvement. This is likely due to the fact that in larger parking lots there is more area to cover and thus the agent can benefit more from being able to see more of the environment at any given time. However, since the total number of steps taken is also larger in larger parking lots, the percentage improvement is smaller. 

The relationship observed was clearly linear and the relationship can be seen in Table~\ref{tab:radius-linear-fit}. For the small, medium, and large parking lots the cost savings per radius increase was found to be $9.30$, $29.51$, and $50.27$ respectively when averaged across the three obstacle distributions. It is interesting to note that the savings seem as though they may scale linearly with the size of the parking lot as well.



%--------------------------------
\subsection{Discussion of Tradeoffs and Limitations}

Describe the key insights of your results.  Discuss limitations.


%==========================================================
%==========================================================
\section{What I learned}

Please describe here a few things you learned from this project.  

\begin{itemize}
    \item \textless replace with new item \textgreater
    \item \textless replace with new item \textgreater
    \item \textless replace with new item \textgreater
    \item \textless replace with new item \textgreater
\end{itemize}



\clearpage  %leave this command here so the tables and figures start on a new page
%==========================================================
%==========================================================
\section{Summary Figures and Tables}
\label{sec:figures-and-tables}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/view_size_all.png}
    \caption{Effect of viewing distance on the ability of the agent to find their car across all trials.}
    \label{fig:viewing-distance-all}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figs/view_size_combo.png}
    \caption{Effect of viewing distance on the ability of the agent to find their car averaged across obstacle distributions.}
    \label{fig:viewing-distance-combo}
\end{figure}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\toprule
\textbf{Board Size / Scheme} & \textbf{Slope} & \textbf{Intercept} & $\mathbf{R^{2}}$ \\
\midrule
Small Normal      & -4.80  & 65.38  & 0.98 \\
Small Many Small  & -4.68  & 64.85  & 0.98 \\
Small Big         & -4.46  & 62.23  & 0.98 \\
\midrule
Medium Normal     & -13.75 & 284.72 & 0.99 \\
Medium Many Small & -15.26 & 294.45 & 0.99 \\
Medium Big        & -15.25 & 297.56 & 0.97 \\
\midrule
Large Normal      & -25.32 & 664.00 & 0.99 \\
Large Many Small  & -25.76 & 663.14 & 1.00 \\
Large Big         & -24.33 & 654.07 & 1.00 \\
\bottomrule
\end{tabular}
\caption{Linear fit parameters for game length vs. diameter across board sizes and obstacle schemes.}
\label{tab:radius-linear-fit}
\end{table}


%==========================================================
%==========================================================
\bibliography{aaai25}


%==========================================================
%==========================================================
%==========================================================
%==========================================================
\clearpage    %leave this command here so the appendices start on a new page
\appendix

\begin{center}
{\Large Appendix}
\end{center}

Should you need to, you can add sections here for additional content.

%==========================================================
%==========================================================
\section{Large Tables or Figures go here}

Table~\ref{tbl:example} shows an example table using the \textbackslash{table*} environment. 
Similarly, Figure~\ref{fig:example} shows an example large figure using the \textbackslash{figure*} environment.  

\begin{table*}
\centering
\begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|p{3cm}|  }
 \hline
 \multicolumn{4}{|c|}{Country List} \\
 \hline
 Country Name or Area Name& ISO ALPHA 2 Code &ISO ALPHA 3 Code&ISO numeric Code\\
 \hline
 Afghanistan   & AF    &AFG&   004\\
 Aland Islands&   AX  & ALA   &248\\
 Albania &AL & ALB&  008\\
 Algeria    &DZ & DZA&  012\\
 American Samoa&   AS  & ASM&016\\
 Andorra& AD  & AND   &020\\
 Angola& AO  & AGO&024\\
 Afghanistan   & AF    &AFG&   004\\
 Aland Islands&   AX  & ALA   &248\\
 Albania &AL & ALB&  008\\
 Algeria    &DZ & DZA&  012\\
 American Samoa&   AS  & ASM&016\\
 Andorra& AD  & AND   &020\\
 Angola& AO  & AGO&024\\
 Afghanistan   & AF    &AFG&   004\\
 Aland Islands&   AX  & ALA   &248\\
 Albania &AL & ALB&  008\\
 Algeria    &DZ & DZA&  012\\
 American Samoa&   AS  & ASM&016\\
 Andorra& AD  & AND   &020\\
 Angola& AO  & AGO&024\\
 Afghanistan   & AF    &AFG&   004\\
 Aland Islands&   AX  & ALA   &248\\
 Albania &AL & ALB&  008\\
 Algeria    &DZ & DZA&  012\\
 American Samoa&   AS  & ASM&016\\
 Andorra& AD  & AND   &020\\
 Angola& AO  & AGO&024\\
 \hline
\end{tabular}
\caption{Here is a caption for this example table, which came from the overleaf help documents at \tinyurl{https://www.overleaf.com/learn/latex/Tables}.  }
\label{tbl:example}
\end{table*}

\begin{figure*}
    \centering
    \includegraphics[width=0.5\linewidth]{figs/ssp.png}
    \caption{Here is a caption for this figure that you probably recognize. }
    \label{fig:example}
\end{figure*}

\end{document}
